{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score, f1_score,roc_auc_score,accuracy_score, confusion_matrix, roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import helper_functions as hf\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "seed = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_pickle('train_set.pkl')\n",
    "data_test = pd.read_pickle('test_set.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clothing_ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "      <th>RAW_Text</th>\n",
       "      <th>review_len</th>\n",
       "      <th>Positive_fb_count</th>\n",
       "      <th>Division</th>\n",
       "      <th>Department</th>\n",
       "      <th>Class</th>\n",
       "      <th>Positively_rated</th>\n",
       "      <th>Reco</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_ind</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19245</th>\n",
       "      <td>829</td>\n",
       "      <td>34</td>\n",
       "      <td>flirty and fun</td>\n",
       "      <td>i am 5 5   145 lbs  a cup  depending on the st...</td>\n",
       "      <td>I am 5'5\", 145 lbs, a cup. depending on the st...</td>\n",
       "      <td>504</td>\n",
       "      <td>6</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22446</th>\n",
       "      <td>768</td>\n",
       "      <td>41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>so thin and see thru it s not even wearable in...</td>\n",
       "      <td>So thin and see thru it's not even wearable in...</td>\n",
       "      <td>188</td>\n",
       "      <td>4</td>\n",
       "      <td>Initmates</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>Lounge</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3813</th>\n",
       "      <td>792</td>\n",
       "      <td>29</td>\n",
       "      <td>cute   comfy</td>\n",
       "      <td>just bought these today and they are super sof...</td>\n",
       "      <td>Just bought these today and they are super sof...</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>Initmates</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>Sleep</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22549</th>\n",
       "      <td>850</td>\n",
       "      <td>52</td>\n",
       "      <td>sweet top</td>\n",
       "      <td>lightweight silk with sweet details  ruffles  ...</td>\n",
       "      <td>Lightweight silk with sweet details (ruffles) ...</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3417</th>\n",
       "      <td>1056</td>\n",
       "      <td>24</td>\n",
       "      <td>cute capris  fit great</td>\n",
       "      <td>i bought the size 27 in these   i m usually a ...</td>\n",
       "      <td>I bought the size 27 in these - i'm usually a ...</td>\n",
       "      <td>239</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              clothing_ID  Age                   Title  \\\n",
       "original_ind                                             \n",
       "19245                 829   34          flirty and fun   \n",
       "22446                 768   41                     NaN   \n",
       "3813                  792   29            cute   comfy   \n",
       "22549                 850   52               sweet top   \n",
       "3417                 1056   24  cute capris  fit great   \n",
       "\n",
       "                                                           Text  \\\n",
       "original_ind                                                      \n",
       "19245         i am 5 5   145 lbs  a cup  depending on the st...   \n",
       "22446         so thin and see thru it s not even wearable in...   \n",
       "3813          just bought these today and they are super sof...   \n",
       "22549         lightweight silk with sweet details  ruffles  ...   \n",
       "3417          i bought the size 27 in these   i m usually a ...   \n",
       "\n",
       "                                                       RAW_Text  review_len  \\\n",
       "original_ind                                                                  \n",
       "19245         I am 5'5\", 145 lbs, a cup. depending on the st...         504   \n",
       "22446         So thin and see thru it's not even wearable in...         188   \n",
       "3813          Just bought these today and they are super sof...         286   \n",
       "22549         Lightweight silk with sweet details (ruffles) ...         111   \n",
       "3417          I bought the size 27 in these - i'm usually a ...         239   \n",
       "\n",
       "              Positive_fb_count        Division Department    Class  \\\n",
       "original_ind                                                          \n",
       "19245                         6  General Petite       Tops  Blouses   \n",
       "22446                         4       Initmates   Intimate   Lounge   \n",
       "3813                          0       Initmates   Intimate    Sleep   \n",
       "22549                         0         General       Tops  Blouses   \n",
       "3417                          0  General Petite    Bottoms    Pants   \n",
       "\n",
       "              Positively_rated  Reco  \n",
       "original_ind                          \n",
       "19245                        1     1  \n",
       "22446                        0     0  \n",
       "3813                         1     1  \n",
       "22549                        1     1  \n",
       "3417                         1     1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(data_train.RAW_Text)\n",
    "y = np.array(data_train.Positively_rated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer()\n",
    "#parameters to tune: n_gram\n",
    "#We chose not to tune min_df as the reviews tend to be short so repeating words should be rare except stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vect = vect.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegressionCV(Cs = [1,5,10],cv = 5,penalty =  'l2',max_iter = 500,random_state = seed,\n",
    "         multi_class = 'ovr')\n",
    "fitted_model,results = hf.model_fit_train_score_skf(model,X_vect, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.879 \n",
      "F1 score: 0.924 \n",
      "AUC score: 0.931\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {results['Accuracy_mean']:.3f} \\nF1 score: {results['F1_mean']:.3f} \\nAUC score: {results['AUC_mean']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_model.C_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs:\n",
      "['disappointed' 'wanted' 'cheap' 'huge' 'unflattering' 'bad' 'returned'\n",
      " 'returning' 'however' 'poor']\n",
      "\n",
      "Largest Coefs: \n",
      "['perfect' 'love' 'comfortable' 'compliments' 'perfectly' 'great'\n",
      " 'sometimes' 'little' 'glad' 'beautifully']\n"
     ]
    }
   ],
   "source": [
    "#try to see the \n",
    "feature_names = np.array(vect.get_feature_names())\n",
    "\n",
    "# Sort the coefficients from the model\n",
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "\n",
    "# Find the 10 smallest and 10 largest coefficients\n",
    "# The 10 largest coefficients are being indexed using [:-11:-1] \n",
    "# so the list returned is in order of largest to smallest\n",
    "print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now let's explore if removing stopwords or lemmatization has impact on the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "stopwords = list(spacy.lang.en.stop_words.STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemma_and_stop (text):\n",
    "    docs = nlp.pipe(text)\n",
    "    lemma = []\n",
    "    lemma_and_stop = []\n",
    "\n",
    "    for doc in docs:\n",
    "        if doc.is_parsed:\n",
    "            lemma.append(\" \".join([n.lemma_ for n in doc]))\n",
    "            lemma_and_stop.append(\" \".join([n.lemma_ for n in doc if n.is_stop == False]))\n",
    "        else:\n",
    "            # We want to make sure that the lists of parsed results have the\n",
    "            # same number of entries of the original Dataframe, so add some blanks in case the parse fails\n",
    "            lemma.append(None)\n",
    "            lemma_and_stop.append(None)\n",
    "    return lemma,lemma_and_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_X,lem_and_stop_X = lemma_and_stop(data_train.RAW_Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer()\n",
    "X_vect_lemma = vect.fit_transform(lemma_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegressionCV(Cs = [0.5,1,5,10],cv = 5,penalty =  'l2',max_iter = 500,random_state = seed,\n",
    "         multi_class = 'ovr')\n",
    "fitted_model,results = hf.model_fit_train_score_skf(model,X_vect_lemma, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.877 \n",
      "F1 score: 0.922 \n",
      "AUC score: 0.925\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {results['Accuracy_mean']:.3f} \\nF1 score: {results['F1_mean']:.3f} \\nAUC score: {results['AUC_mean']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_model.C_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer()\n",
    "X_vect_lemma_stop = vect.fit_transform(lem_and_stop_X)\n",
    "\n",
    "model = LogisticRegressionCV(Cs = [0.5,1,5,10],cv = 5,penalty =  'l2',max_iter = 500,random_state = seed,\n",
    "         multi_class = 'ovr')\n",
    "\n",
    "fitted_model,results = hf.model_fit_train_score_skf(model,X_vect_lemma_stop, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.868 \n",
      "F1 score: 0.917 \n",
      "AUC score: 0.912\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {results['Accuracy_mean']:.3f} \\nF1 score: {results['F1_mean']:.3f} \\nAUC score: {results['AUC_mean']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same conclusion as BOW model, lemmatization and stop words removal does not help improving the model performance\n",
    "\n",
    "We will explore fitting MNB and SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "fitted_model,results = hf.model_fit_train_score_skf(clf,X_vect, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.783 \n",
      "F1 score: 0.877 \n",
      "AUC score: 0.909\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {results['Accuracy_mean']:.3f} \\nF1 score: {results['F1_mean']:.3f} \\nAUC score: {results['AUC_mean']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_2 = TfidfVectorizer(ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vect2 = vect_2.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegressionCV(Cs = [0.1,1,5,10],cv = 5,penalty =  'l2',max_iter = 500,random_state = seed,\n",
    "         multi_class = 'ovr')\n",
    "fitted_model,results = hf.model_fit_train_score_skf(model,X_vect2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.889 \n",
      "F1 score: 0.930 \n",
      "AUC score: 0.941\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {results['Accuracy_mean']:.3f} \\nF1 score: {results['F1_mean']:.3f} \\nAUC score: {results['AUC_mean']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs:\n",
      "['disappointed' 'to love' 'cheap' 'huge' 'not' 'not flattering'\n",
      " 'unflattering' 'returned' 'was' 'however']\n",
      "\n",
      "Largest Coefs: \n",
      "['perfect' 'love' 'comfortable' 'great' 'not too' 'love this' 'perfectly'\n",
      " 'fits' 'little' 'compliments']\n"
     ]
    }
   ],
   "source": [
    "#try to see the \n",
    "feature_names2 = np.array(vect_2.get_feature_names())\n",
    "\n",
    "# Sort the coefficients from the model\n",
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "\n",
    "# Find the 10 smallest and 10 largest coefficients\n",
    "# The 10 largest coefficients are being indexed using [:-11:-1] \n",
    "# so the list returned is in order of largest to smallest\n",
    "print('Smallest Coefs:\\n{}\\n'.format(feature_names2[sorted_coef_index[:10]]))\n",
    "print('Largest Coefs: \\n{}'.format(feature_names2[sorted_coef_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None,\n",
       "            {'predictions': [array([1, 0, 1, ..., 0, 0, 0], dtype=int64),\n",
       "              array([0, 1, 1, ..., 1, 0, 1], dtype=int64),\n",
       "              array([1, 1, 1, ..., 0, 1, 0], dtype=int64),\n",
       "              array([1, 1, 1, ..., 1, 0, 0], dtype=int64),\n",
       "              array([1, 1, 1, ..., 1, 1, 0], dtype=int64)],\n",
       "             'predict_proba': [array([0.80219119, 0.01449929, 0.93160834, ..., 0.01588034, 0.06728294,\n",
       "                     0.09835457]),\n",
       "              array([0.40936969, 0.98746757, 0.98231115, ..., 0.63226826, 0.22601763,\n",
       "                     0.81526476]),\n",
       "              array([0.99710456, 0.99040941, 0.97165812, ..., 0.28169199, 0.98061749,\n",
       "                     0.17454011]),\n",
       "              array([0.99711825, 0.98876105, 0.99753555, ..., 0.50540558, 0.0312755 ,\n",
       "                     0.23795048]),\n",
       "              array([0.99519003, 0.99778335, 0.97877786, ..., 0.72942468, 0.87494089,\n",
       "                     0.46656751])],\n",
       "             'Accuracy_mean': 0.8888100336932595,\n",
       "             'F1_mean': 0.9302648349439805,\n",
       "             'AUC_mean': 0.9411571547353665,\n",
       "             'Accuracy_std': 0.008044108538934286,\n",
       "             'F1_std': 0.004724981077805905,\n",
       "             'AUC_std': 0.006566989091513552})"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
